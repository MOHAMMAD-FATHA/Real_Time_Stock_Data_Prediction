{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import csv\n",
    "import requests\n",
    "import os\n",
    "from json import dumps\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.sql.functions import percent_rank\n",
    "from pyspark.sql import Window\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "spark = SparkSession.builder.appName(\"Stock Data Prediction\").getOrCreate()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 23:25:00,151 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2021-12-04 23:25:06,953 WARN util.Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "2021-12-04 23:25:06,955 WARN util.Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "2021-12-04 23:25:06,956 WARN util.Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "CSV_URL = 'https://www.alphavantage.co/query?function=TIME_SERIES_INTRADAY_EXTENDED&symbol=IBM&interval=1min&slice=year1month1&apikey= 2AOXSCUJQ3NQNKSG'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The api key data is stored in csv file and that file sent to hdfs through terminal"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "with requests.Session() as s:\n",
    "    download = s.get(CSV_URL)\n",
    "    decoded_content = download.content.decode('utf-8')\n",
    "    cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
    "    my_list = list(cr)\n",
    "with open('data.csv', 'w') as csv_file: \n",
    "    csv_writer = csv.writer(csv_file, delimiter=\",\")\n",
    "    for row in my_list:\n",
    "        csv_writer.writerow(row)\n",
    "    csv_file.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fetch the stock data csv file from hdfs and stored it as dataframe"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df = spark.read.csv(\"hdfs://localhost:9000/Spark/StockDataPrediction/StockData.csv\",header=True)\n",
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(time='2021-12-03 19:40:00', open='119.11', high='119.11', low='119.11', close='119.11', volume='307')"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df.describe()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DataFrame[summary: string, time: string, open: string, high: string, low: string, close: string, volume: string]"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "df.show(4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+------+------+------+------+------+\n",
      "|               time|  open|  high|   low| close|volume|\n",
      "+-------------------+------+------+------+------+------+\n",
      "|2021-12-03 19:40:00|119.11|119.11|119.11|119.11|   307|\n",
      "|2021-12-03 18:40:00|119.05|119.05|119.05|119.05|   100|\n",
      "|2021-12-03 18:14:00|119.05|119.05|119.05|119.05|   267|\n",
      "|2021-12-03 18:09:00|119.06|119.06|119.05|119.05|   310|\n",
      "+-------------------+------+------+------+------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Casting the string values to double to prepare train and test data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "df2 = df\\\n",
    "    .withColumn(\"open\",col(\"Open\").cast(\"double\"))\\\n",
    "    .withColumn(\"high\",col(\"High\").cast(\"double\"))\\\n",
    "    .withColumn(\"low\",col(\"Low\").cast(\"double\"))\\\n",
    "    .withColumn(\"close\",col(\"Close\").cast(\"double\"))\\\n",
    "    .withColumn(\"volume\",col(\"Volume\").cast(\"double\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "df2.head()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Row(time='2021-12-03 19:40:00', open=119.11, high=119.11, low=119.11, close=119.11, volume=307.0)"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Creating the vectors from features. Apache MLib takes the input in the form of vectors="
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "featureassembler=VectorAssembler(inputCols=[\"open\",\"high\",\"low\"],outputCol=\"features\")\n",
    "output=featureassembler.transform(df2)\n",
    "output.select(\"features\").show(5,truncate=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+----------------------+\n",
      "|features              |\n",
      "+----------------------+\n",
      "|[119.11,119.11,119.11]|\n",
      "|[119.05,119.05,119.05]|\n",
      "|[119.05,119.05,119.05]|\n",
      "|[119.06,119.06,119.05]|\n",
      "|[119.05,119.05,119.05]|\n",
      "+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "finalized_data=output.select(\"time\",\"features\",\"close\").sort(\"time\",ascending=True)\n",
    "finalized_data.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+-------------+\n",
      "|               time|            features|        close|\n",
      "+-------------------+--------------------+-------------+\n",
      "|2021-11-04 04:07:00|[121.895807821,12...|121.353171687|\n",
      "|2021-11-04 04:08:00|[121.353171687,12...|121.353171687|\n",
      "|2021-11-04 04:11:00|[121.728083925,12...|121.728083925|\n",
      "|2021-11-04 04:14:00|[121.550493918,12...|121.550493918|\n",
      "|2021-11-04 04:24:00|[121.353171687,12...|121.353171687|\n",
      "+-------------------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "Splitting data into training and testing data and Final data for real time stock data created"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "final_data = finalized_data.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(\"time\")))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train_df = final_data.where(\"rank <= .8\").drop(\"rank\")\n",
    "train_df.show(10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 23:27:45,924 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+-------------+\n",
      "|               time|            features|        close|\n",
      "+-------------------+--------------------+-------------+\n",
      "|2021-11-04 04:07:00|[121.895807821,12...|121.353171687|\n",
      "|2021-11-04 04:08:00|[121.353171687,12...|121.353171687|\n",
      "|2021-11-04 04:11:00|[121.728083925,12...|121.728083925|\n",
      "|2021-11-04 04:14:00|[121.550493918,12...|121.550493918|\n",
      "|2021-11-04 04:24:00|[121.353171687,12...|121.353171687|\n",
      "|2021-11-04 04:35:00|[121.343305576,12...|121.343305576|\n",
      "|2021-11-04 04:36:00|[121.254510572,12...|121.264376684|\n",
      "|2021-11-04 04:38:00|[121.254510572,12...|121.155849457|\n",
      "|2021-11-04 04:42:00|[121.057188342,12...|121.057188342|\n",
      "|2021-11-04 04:44:00|[121.155849457,12...|121.155849457|\n",
      "+-------------------+--------------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "test_df = final_data.where(\"rank > .8\").drop(\"rank\")\n",
    "test_df.show(10)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 23:28:03,767 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+-------+\n",
      "|               time|            features|  close|\n",
      "+-------------------+--------------------+-------+\n",
      "|2021-11-29 14:42:00|[119.31,119.37,11...| 119.34|\n",
      "|2021-11-29 14:43:00|[119.37,119.3761,...| 119.33|\n",
      "|2021-11-29 14:44:00|[119.32,119.3201,...| 119.24|\n",
      "|2021-11-29 14:45:00|[119.228,119.29,1...|119.275|\n",
      "|2021-11-29 14:46:00|[119.26,119.3,119...| 119.29|\n",
      "|2021-11-29 14:47:00|[119.3,119.31,119...|119.295|\n",
      "|2021-11-29 14:48:00|[119.31,119.31,11...| 119.21|\n",
      "|2021-11-29 14:49:00|[119.22,119.23,11...| 119.22|\n",
      "|2021-11-29 14:50:00|[119.23,119.23,11...| 119.15|\n",
      "|2021-11-29 14:51:00|[119.13,119.2,119...|  119.2|\n",
      "+-------------------+--------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "train_df.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 13:22:39,907 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "7434"
      ]
     },
     "metadata": {},
     "execution_count": 14
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "test_df.count()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 13:22:46,152 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1859"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "type(test_df)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the test data to hdfs as parquet file "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "\n",
    "test_df.write.parquet('RealTimeStockDataPrediction.parquet')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 19:15:47,011 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Building a ML Model (Linear regression)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "linear_reg=LinearRegression(featuresCol='features',labelCol='close')\n",
    "lr_model=linear_reg.fit(train_df)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 23:28:19,690 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-12-04 23:28:20,568 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "2021-12-04 23:28:21,054 WARN util.Instrumentation: [d56eef47] regParam is zero, which might cause numerical instability and overfitting.\n",
      "2021-12-04 23:28:23,435 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "2021-12-04 23:28:23,437 WARN netlib.BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "2021-12-04 23:28:23,821 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeSystemLAPACK\n",
      "2021-12-04 23:28:23,822 WARN netlib.LAPACK: Failed to load implementation from: com.github.fommil.netlib.NativeRefLAPACK\n",
      "2021-12-04 23:28:24,859 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Coefficients: [-0.44724541526933487,0.7175480484697344,0.7297495663223875]\n",
      "Intercept: -0.005938793314908819\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "predDF = lr_model.transform(test_df)\n",
    "predDF.select(\"features\", \"close\",\"prediction\").show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 23:28:35,664 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+--------------------+-------+------------------+\n",
      "|            features|  close|        prediction|\n",
      "+--------------------+-------+------------------+\n",
      "|[119.31,119.37,11...| 119.34|  119.353342014657|\n",
      "|[119.37,119.3761,...| 119.33|119.33818182849971|\n",
      "|[119.32,119.3201,...| 119.24|119.24008895625342|\n",
      "|[119.228,119.29,1...|119.275|119.26693483386249|\n",
      "|[119.26,119.3,119...| 119.29|  119.274393452385|\n",
      "+--------------------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluvating the model using Regression Evaluator"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator = RegressionEvaluator(\n",
    "predictionCol=\"prediction\",\n",
    "labelCol=\"close\",\n",
    "metricName=\"rmse\")\n",
    "rmse = regressionEvaluator.evaluate(predDF)\n",
    "print(f\"Root Mean Squared Error(RMSE) is {rmse:.1f}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 23:28:49,040 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Root Mean Squared Error(RMSE) is 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Save the model to hdfs "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "lr_model.save(\"hdfs://localhost:9000/prediction_stock_price_data_model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "data_frame = predDF.toDF('time', 'features', 'close', 'prediction')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "data_frame.show(5)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 20:17:34,552 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "+-------------------+--------------------+-------+------------------+\n",
      "|               time|            features|  close|        prediction|\n",
      "+-------------------+--------------------+-------+------------------+\n",
      "|2021-11-29 14:42:00|[119.31,119.37,11...| 119.34|  119.353342014657|\n",
      "|2021-11-29 14:43:00|[119.37,119.3761,...| 119.33|119.33818182849971|\n",
      "|2021-11-29 14:44:00|[119.32,119.3201,...| 119.24|119.24008895625342|\n",
      "|2021-11-29 14:45:00|[119.228,119.29,1...|119.275|119.26693483386249|\n",
      "|2021-11-29 14:46:00|[119.26,119.3,119...| 119.29|  119.274393452385|\n",
      "+-------------------+--------------------+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": []
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "# type (data_frame)\n",
    "data_frame.write.parquet('RealTimeStockDataPrediction.parquet')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-12-04 20:21:07,163 WARN window.WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "f9f85f796d01129d0dd105a088854619f454435301f6ffec2fea96ecbd9be4ac"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}